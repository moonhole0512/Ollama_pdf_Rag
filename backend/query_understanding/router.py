import re
import json
from typing import List, Tuple, Dict, Any, Optional, Literal
from pydantic import BaseModel
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.language_models.chat_models import BaseChatModel

# --- LLM-based Query Router ---
class IntelligentRouterOutput(BaseModel):
    """LLMì´ ë°˜í™˜í•  ë¼ìš°íŒ… ë° ì¿¼ë¦¬ ì¬ì‘ì„± ê²°ê³¼ ëª¨ë¸"""
    intent: Literal[
        "concept_definition", 
        "table_of_contents_lookup", 
        "chapter_summary", 
        "general_information_retrieval"
    ]
    rewritten_query: str
    expanded_queries: List[str]
    chapter_number: Optional[int] = None
    
    
LLM_ROUTER_SYSTEM_PROMPT = """You are an expert query analyzer and rewriter for a Retrieval-Augmented Generation (RAG) system.
Your task is to understand the user's query, classify its intent, rewrite it for optimal retrieval, and extract relevant entities.

**1. De-contextualize:**
If the query contains pronouns like 'that', 'this', 'it', 'ì´ê±°', 'ì €ê±°', 'ê·¸ê±°', use the provided chat history to resolve them and create a self-contained, complete question.
- Example (History: "What is the 'reciprocity' principle?", User: "Tell me more about it.") -> Rewritten: "Tell me more about the 'reciprocity' principle."

**2. Classify Intent & Extract Entities:**
Categorize the rewritten query into one of the following intents. If you extract an entity, place it in the corresponding field.
- `concept_definition`: Asks for the definition, explanation, or meaning of a specific term, concept, principle, or strategy. (e.g., "What is cognitive dissonance?", "ì„¤ë“ì˜ 6ê°€ì§€ ì›ì¹™ì´ë€?")
- `table_of_contents_lookup`: Asks for the table of contents, structure, or list of chapters. (e.g., "Show me the table of contents.", "ëª©ì°¨ ë³´ì—¬ì¤˜.")
- `chapter_summary`: Asks to summarize a specific chapter. 
  - **You MUST extract the chapter number (e.g., from 'chapter 3', 'third chapter', '3ì¥') as an integer and put it in the `chapter_number` field.**
- `general_information_retrieval`: All other questions that seek specific information, examples, or general knowledge from the document. This is the default.

**3. Rewrite and Expand:**
- **`rewritten_query`**: Create a clear, concise, and keyword-rich version of the de-contextualized query. This should be the best possible query for a search engine.
- **`expanded_queries`**: Generate 3 additional, diverse search queries based on the original question to improve search recall. These should explore different phrasings, synonyms, or related aspects.

**Output Format:**
You MUST respond with a single, valid JSON object that adheres to the `IntelligentRouterOutput` schema. Do not add any text before or after the JSON.
Example JSON for chapter summary:
{{
  "intent": "chapter_summary",
  "rewritten_query": "Summarize the third chapter about social proof",
  "expanded_queries": [
    "summary of chapter 3",
    "key points of the chapter on social proof",
    "main ideas from the third chapter"
  ],
  "chapter_number": 3
}}

Example JSON for concept definition:
{{
  "intent": "concept_definition",
  "rewritten_query": "Definition and examples of the commitment and consistency principle",
  "expanded_queries": [
    "commitment and consistency principle explained",
    "How does the commitment and consistency rule work?",
    "ì‚¬íšŒì  ì¦ê±°ì˜ ì›ì¹™"
  ],
  "chapter_number": null
}}
"""


def intelligent_query_router(
    query: str, 
    chat_history: List[Tuple[str, str]],
    llm: BaseChatModel
) -> Dict[str, Any]:
    """LLMì„ ì‚¬ìš©í•œ ì§€ëŠ¥í˜• ì¿¼ë¦¬ ë¶„ë¥˜ ë° ì¬ì‘ì„± (ìˆ˜ë™ JSON íŒŒì‹±)"""
    
    history_str = "\n".join([f"Human: {h}\nAI: {a}" for h, a in chat_history])
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", LLM_ROUTER_SYSTEM_PROMPT),
        ("human", "Chat History:\n---\n{history}\n---\n\nUser Query: \"{query}\"")
    ])
    
    chain = prompt | llm | StrOutputParser()
    
    try:
        print("ğŸ§  Calling LLM Router...")
        response_str = chain.invoke({
            "history": history_str,
            "query": query
        })
        
        # LLM ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        match = re.search(r'\{.*\}', response_str, re.DOTALL)
        if not match:
            raise ValueError("LLM did not return a valid JSON object.")
        
        json_str = match.group(0)
        
        # JSON íŒŒì‹± ë° Pydantic ëª¨ë¸ë¡œ ê²€ì¦
        response_data = json.loads(json_str)
        response = IntelligentRouterOutput.model_validate(response_data)

        # ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        output = {
            "type": response.intent,
            "rewritten_query": response.rewritten_query,
            "search_queries": [response.rewritten_query] + response.expanded_queries,
        }
        
        # íŠ¹ìˆ˜ íƒ€ì…ì— í•„ìš”í•œ ì •ë³´ ì¶”ê°€
        if response.intent == "concept_definition":
            output["concept"] = response.rewritten_query.replace("Definition and examples of the", "").strip()
        elif response.intent == "chapter_summary":
            # LLMì´ ì¶”ì¶œí•œ chapter_numberë¥¼ ìš°ì„  ì‚¬ìš©
            if response.chapter_number is not None:
                output["chapter_num"] = str(response.chapter_number)
            else:
                # Fallback: ì›ë³¸ ì¿¼ë¦¬ì—ì„œ ìˆ«ì ì§ì ‘ ì°¾ê¸°
                match_num = re.search(r'\d+', query)
                if match_num:
                    output["chapter_num"] = match_num.group(0)

        # fallback í•¨ìˆ˜ê°€ rewritten_queryë¥¼ ë°˜í™˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¶”ê°€
        if "rewritten_query" not in output:
            output["rewritten_query"] = query

        return output
        
    except Exception as e:
        print(f"--- LLM ROUTER ERROR ---")
        print(f"Error: {e}")
        print("Falling back to legacy rule-based classification.")
        return classify_query_advanced_fallback(query, chat_history)


def classify_query_advanced_fallback(
    query: str, 
    chat_history: List[Tuple[str, str]]
) -> Dict[str, Any]:
    """Fallback: í–¥ìƒëœ ì¿¼ë¦¬ ë¶„ë¥˜ ë° í™•ì¥ (ê¸°ì¡´ ë¡œì§)"""
    
    # ì¿¼ë¦¬ ì „ì²˜ë¦¬
    from backend.retrieval.hybrid_retriever import preprocess_query # Avoid circular import
    query = preprocess_query(query)
    rewritten_query = query # fallbackì—ì„œëŠ” ì¬ì‘ì„± ê¸°ëŠ¥ ì—†ìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    query_lower = query.lower()
    
    # 1. ê°œë… ì •ì˜ ì§ˆë¬¸ ê°ì§€
    definition_patterns = [
        r'(.+?)(ì´ë€|ë€|ì´ë¼ëŠ”|ë¼ëŠ”|ì€ ë¬´ì—‡|ëŠ” ë¬´ì—‡|ì´ ë­|ê°€ ë­)',
        r'(.+?)(ì— ëŒ€í•´|ì—ëŒ€í•´).+(ì„¤ëª…|ë§í•´|ì•Œë ¤)',
        r'(ì „ëµ|ì›ë¦¬|ë²•ì¹™|íš¨ê³¼|ë°©ë²•|ê¸°ë²•).+(ë­|ë¬´ì—‡)',
    ]
    for pattern in definition_patterns:
        match = re.search(pattern, query_lower)
        if match:
            concept = match.group(1).strip()
            concept_clean = re.sub(r'\s+(ì—|ì˜|ë¥¼|ì„|ê°€|ì´|ì€|ëŠ”)$', '', concept)
            return {
                "type": "concept_definition", "concept": concept_clean,
                "rewritten_query": rewritten_query,
                "search_queries": [query, concept_clean, f'{concept_clean} ì „ëµ', f'{concept_clean} ë°©ë²•']
            }
    
    # 2. ëª©ì°¨ ì§ˆë¬¸
    toc_patterns = [r'ëª©ì°¨', r'ì°¨ë¡€', r'êµ¬ì„±', r'table of contents', r'toc']
    if any(re.search(p, query_lower) for p in toc_patterns):
        return {"type": "table_of_contents_lookup", "rewritten_query": rewritten_query, "search_queries": [query]}
    
    # 3. ì±•í„° ìš”ì•½
    summary_match = re.search(r'(summarize|ìš”ì•½)\s*(?:chapter|ì¥)?\s*(\d{1,2})', query_lower)
    if summary_match:
        return {
            "type": "chapter_summary", "chapter_num": summary_match.group(2),
            "rewritten_query": rewritten_query, "search_queries": [query]
        }
    
    # 4. ì¼ë°˜ ì£¼ì œ ì§ˆë¬¸
    return {
        "type": "general_information_retrieval",
        "rewritten_query": rewritten_query,
        "search_queries": [query, f'{query} ì„¤ëª…', f'{query} ì˜ˆì‹œ']
    }

